{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from detection_utils import random_label\n",
    "from detection_evaluate import single_metric_fpr_tpr, combined_metric_fpr_tpr\n",
    "from detection_baseline import targeted_vals, untargeted_vals\n",
    "\n",
    "# from utils import transform\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n",
      "=> load checkpoint found at /Users/albertwen/Downloads/mae_data/resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"/Users/albertwen/Downloads/mae_data/resnet50.pth\"\n",
    "\n",
    "# Setting the seed\n",
    "# pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "pretrained_model = torchvision.models.resnet50(pretrained=True)\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "if CHECKPOINT_PATH:\n",
    "    if os.path.isfile(CHECKPOINT_PATH):\n",
    "        checkpoint = torch.load(CHECKPOINT_PATH) \n",
    "        # model.load_state_dict(checkpoint['state_dict'])  #['state_dict']\n",
    "        pretrained_model.load_state_dict(checkpoint)  #['state_dict']\n",
    "        print(\"=> load checkpoint found at {}\".format(CHECKPOINT_PATH))\n",
    "        # print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "        #       .format(args.resume, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(CHECKPOINT_PATH))\n",
    "# No gradients needed for the network\n",
    "pretrained_model.eval()\n",
    "for p in pretrained_model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = 0.1 # can be [0.1, 0.2]\n",
    "untargeted_step_threshold = 1000\n",
    "criterions = {0.1: (0.190, 35, untargeted_step_threshold), 0.2: (1.77, 22, untargeted_step_threshold)} # pre-defined in paper's code\n",
    "dataset = \"imagenet\"\n",
    "attacks = [\"fgsm_4\", \"fgsm_8\", \"pgd_8\"]\n",
    "real_d = \"/Users/albertwen/Downloads/mae_data/ImageNet-Data/val\"\n",
    "adv_d = \"/Users/albertwen/Downloads/mae_data/ImageNet-Data/attack/val\"\n",
    "\n",
    "noise_radius = 0.1\n",
    "targeted_lr = 0.005 \n",
    "\n",
    "# TODO: go through paper and re-evaluate , different result for pgd and cw, better for cw to try for that\n",
    "targeted_radius = 0.03\n",
    "untargeted_radius = 0.03\n",
    "untargeted_lr = 0.1\n",
    "\n",
    "det_opt = \"targeted\" # can be [\"targeted\", \"untargeted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# testing for real vs attacked images\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m real_steps \u001b[39m=\u001b[39m targeted_vals(pretrained_model, \u001b[39m\"\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mreal\u001b[39;49m\u001b[39m\"\u001b[39;49m, real_d, adv_d, targeted_lr\u001b[39m=\u001b[39;49mtargeted_lr, t_radius\u001b[39m=\u001b[39;49mtargeted_radius)\n\u001b[1;32m      3\u001b[0m \u001b[39m# real_steps\u001b[39;00m\n",
      "File \u001b[0;32m~/GitHub/MAE-Reverse-Adversarial/detection_baseline.py:147\u001b[0m, in \u001b[0;36mtargeted_vals\u001b[0;34m(model, dataset, attack, real_dir, adv_dir, targeted_lr, t_radius)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[39mif\u001b[39;00m label \u001b[39m!=\u001b[39m predicted_label:\n\u001b[1;32m    145\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m         val \u001b[39m=\u001b[39m targeted_detection(model, img, label, dataset, targeted_lr, t_radius)\n\u001b[1;32m    148\u001b[0m         vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((vals, [val]))\n\u001b[1;32m    150\u001b[0m \u001b[39melse\u001b[39;00m: \n",
      "File \u001b[0;32m~/GitHub/MAE-Reverse-Adversarial/detection_baseline.py:50\u001b[0m, in \u001b[0;36mtargeted_detection\u001b[0;34m(model, img, true_label, dataset, lr, t_radius, cap, margin, use_margin)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     49\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target_l)\n\u001b[0;32m---> 50\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     52\u001b[0m x_var\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclamp(x_var \u001b[39m-\u001b[39m lr \u001b[39m*\u001b[39m x_var\u001b[39m.\u001b[39mgrad\u001b[39m.\u001b[39mdata, \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m x_var\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mclamp(x_var \u001b[39m-\u001b[39m img, \u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mt_radius, \u001b[39mmax\u001b[39m\u001b[39m=\u001b[39mt_radius) \u001b[39m+\u001b[39m img\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/tensor.py:245\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    237\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    238\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    239\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    243\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    244\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 245\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/autograd/__init__.py:145\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m--> 145\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(\n\u001b[1;32m    146\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    147\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# testing for real vs attacked images\n",
    "real_steps = targeted_vals(pretrained_model, \"imagenet\", \"real\", real_d, adv_d, targeted_lr=targeted_lr, t_radius=targeted_radius)\n",
    "# real_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_steps) # there are 101 total images in this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_steps_shark = targeted_vals(pretrained_model, \"imagenet\", \"real\", \"/Users/albertwen/Downloads/mae_data/ImageNet-Data/test_val3/\", adv_d, targeted_lr=targeted_lr, t_radius=targeted_radius)\n",
    "real_steps_shark\n",
    "\n",
    "# TODO: test the prediction power on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_steps_shark = targeted_vals(pretrained_model, \"imagenet\", \"real\", \"/Users/albertwen/Downloads/mae_data/ImageNet-Data/test_val2\", adv_d, targeted_lr=targeted_lr, t_radius=targeted_radius)\n",
    "real_steps_shark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the number of successes in targeted detection -91\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgsm4_steps = targeted_vals(pretrained_model, \"imagenet\", \"fgsm_4\", real_d, real_d, targeted_lr=targeted_lr, t_radius=targeted_radius)\n",
    "fgsm4_steps\n",
    "\n",
    "# fake testing, passed in real dir to see if fgsm4_steps = real_steps, .e. attack pipeline is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the number of successes in targeted detection -44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_fgsm4_steps = targeted_vals(pretrained_model, \"imagenet\", \"fgsm_4\", real_d, adv_d, targeted_lr=targeted_lr, t_radius=targeted_radius)\n",
    "correct_fgsm4_steps\n",
    "\n",
    "# fake testing, passed in real dir to see if fgsm4_steps = real_steps, .e. attack pipeline is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m single_metric_fpr_tpr(fpr, \n\u001b[1;32m      2\u001b[0m                       criterions, \n\u001b[1;32m      3\u001b[0m                       pretrained_model, \n\u001b[1;32m      4\u001b[0m                       dataset, \n\u001b[1;32m      5\u001b[0m                       attacks, \n\u001b[1;32m      6\u001b[0m                       real_d, \n\u001b[1;32m      7\u001b[0m                       adv_d, \n\u001b[1;32m      8\u001b[0m                       noise_radius, \n\u001b[1;32m      9\u001b[0m                       targeted_lr, \n\u001b[1;32m     10\u001b[0m                       targeted_radius, \n\u001b[1;32m     11\u001b[0m                       untargeted_lr, \n\u001b[1;32m     12\u001b[0m                       untargeted_radius, \n\u001b[1;32m     13\u001b[0m                       opt\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtargeted\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/GitHub/MAE-Reverse-Adversarial/detection_evaluate.py:28\u001b[0m, in \u001b[0;36msingle_metric_fpr_tpr\u001b[0;34m(fpr, criterions, model, dataset, attacks, real_dir, adv_dir, n_radius, targeted_lr, t_radius, untargeted_lr, u_radius, opt)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msingle_metric_fpr_tpr\u001b[39m(fpr, \n\u001b[1;32m     11\u001b[0m                           criterions, \n\u001b[1;32m     12\u001b[0m                           model, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[39m#     threshold = criterions[fpr][0]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[39m#     print(\"this is l1 norm for real images\", target)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[39mif\u001b[39;00m opt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtargeted\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 28\u001b[0m         target \u001b[39m=\u001b[39m targeted_vals(model, dataset, \u001b[39m\"\u001b[39;49m\u001b[39mreal\u001b[39;49m\u001b[39m\"\u001b[39;49m, real_dir, adv_dir, targeted_lr, t_radius)\n\u001b[1;32m     29\u001b[0m         threshold \u001b[39m=\u001b[39m criterions[fpr][\u001b[39m1\u001b[39m]\n\u001b[1;32m     30\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnumber of steps for targeted attacks on real images\u001b[39m\u001b[39m'\u001b[39m, target)\n",
      "File \u001b[0;32m~/GitHub/MAE-Reverse-Adversarial/detection_baseline.py:187\u001b[0m, in \u001b[0;36mtargeted_vals\u001b[0;34m(model, dataset, attack, real_dir, adv_dir, targeted_lr, t_radius)\u001b[0m\n\u001b[1;32m    185\u001b[0m image_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(adv_dir, attack)\n\u001b[1;32m    186\u001b[0m \u001b[39massert\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(image_dir)\n\u001b[0;32m--> 187\u001b[0m atk_dataset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mImageFolder(root\u001b[39m=\u001b[39mimage_dir, transform\u001b[39m=\u001b[39mplain_transforms)\n\u001b[1;32m    188\u001b[0m atk_dataset_loader \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mDataLoader(atk_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m (atk_dataset_loader):\n",
      "File \u001b[0;32m~/GitHub/MAE-Reverse-Adversarial/detection_baseline.py:65\u001b[0m, in \u001b[0;36mtargeted_detection\u001b[0;34m(model, img, true_label, dataset, lr, t_radius, cap, margin, use_margin)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m counter\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39muntargeted_detection\u001b[39m(model, \n\u001b[1;32m     60\u001b[0m                          img, \n\u001b[1;32m     61\u001b[0m                          true_label, \n\u001b[1;32m     62\u001b[0m                          dataset, \n\u001b[1;32m     63\u001b[0m                          lr, \n\u001b[1;32m     64\u001b[0m                          u_radius, \n\u001b[0;32m---> 65\u001b[0m                          cap\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, \n\u001b[1;32m     66\u001b[0m                          margin\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, \n\u001b[1;32m     67\u001b[0m                          use_margin\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     68\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     69\u001b[0m     \u001b[39m# x_var = torch.autograd.Variable(img.clone().cuda(), requires_grad=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torchvision/models/resnet.py:249\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torchvision/models/resnet.py:238\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    235\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[1;32m    237\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 238\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer2(x)\n\u001b[1;32m    239\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[1;32m    240\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/container.py:119\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    118\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 119\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torchvision/models/resnet.py:132\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[1;32m    130\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m--> 132\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(out)\n\u001b[1;32m    133\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn3(out)\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/conv.py:399\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 399\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/conv.py:395\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    392\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    393\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    394\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 395\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    396\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# targeted single metric\n",
    "single_metric_fpr_tpr(fpr, \n",
    "                      criterions, \n",
    "                      pretrained_model, \n",
    "                      dataset, \n",
    "                      attacks, \n",
    "                      real_d, \n",
    "                      adv_d, \n",
    "                      noise_radius, \n",
    "                      targeted_lr, \n",
    "                      targeted_radius, \n",
    "                      untargeted_lr, \n",
    "                      untargeted_radius, \n",
    "                      opt=\"targeted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/y9/l2z6fxk97j32t00jbm20rm6w0000gn/T/ipykernel_41765/25867023.py\", line 1, in <module>\n",
      "    single_metric_fpr_tpr(fpr,\n",
      "  File \"/Users/albertwen/GitHub/MAE-Reverse-Adversarial/detection_evaluate.py\", line 32, in single_metric_fpr_tpr\n",
      "    target = untargeted_vals(model, dataset, \"real\", real_dir, adv_dir, untargeted_lr, u_radius)\n",
      "  File \"/Users/albertwen/GitHub/MAE-Reverse-Adversarial/detection_baseline.py\", line 232, in untargeted_vals\n",
      "  File \"/Users/albertwen/GitHub/MAE-Reverse-Adversarial/detection_baseline.py\", line 104, in untargeted_detection\n",
      "    if attack == \"real\":\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 249, in forward\n",
      "    return self._forward_impl(x)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 238, in _forward_impl\n",
      "    x = self.layer2(x)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 119, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torchvision/models/resnet.py\", line 139, in forward\n",
      "    out = self.relu(out)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2052, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/Users/albertwen/opt/anaconda3/envs/ml/lib/python3.8/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "single_metric_fpr_tpr(fpr, \n",
    "                      criterions, \n",
    "                      pretrained_model, \n",
    "                      dataset, \n",
    "                      attacks, \n",
    "                      real_d, \n",
    "                      adv_d, \n",
    "                      noise_radius, \n",
    "                      targeted_lr, \n",
    "                      targeted_radius, \n",
    "                      untargeted_lr, \n",
    "                      untargeted_radius, \n",
    "                      opt=\"untargeted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9992779686633b1a0c917c3f6317d760e57d78a77247aa4b25ad344de6939a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
